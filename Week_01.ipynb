{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Assignment week 01\n",
    "\n",
    "## Author: Karina Diaz\n",
    "\n",
    "Study the Tutorial tutorial_cluster_scanpy_object and the tutorial_Clustering_Methods\n",
    "\n",
    "Write a brief summary about the following:\n",
    "\n",
    "-\t1. What are common preprocessing steps? Explain for each step why and when you should execute this step and when not.\n",
    "-\t2. What visualization methods are used in the cluster methods tutorial? Explain why the selected method is the most appropriate method for the visualization. Bonus points: do this as well for the scanpy tutorial.\n",
    "-\t3. What performance/evaluation metrics are in the cluster methods tutorial? Explain why the used methods are the most appropriate method for the evaluation.\n",
    "\n",
    "\n",
    "Bonus:\n",
    "You practice the steps yourself with the breast_cancer dataset (clustering_data.csv)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Common preprocessing steps between tutorials:\n",
    "\n",
    "-----\n",
    "A.- The **examination and data inspection** of the datasets from both tutorials are checked. This is made to have an overview of the entries, how the data looks like and to understand how the dataset is composed. You should *always* do this step, to get a general overview. \n",
    " \n",
    "The commands applied will depend if a specific package is requiered or not.  \n",
    "For example in the ***scanpy tutorial*** specific commands are used (`obs_names`, `var_names`,`obs.head`, `obs.shape`, `.var`, etc ).  \n",
    "\n",
    "If there is no requirement of a speficic package, the ones from pandas can be used (`head`, `shape`, `dtypes`, etc) like in the ***clustering tutorial***. \n",
    "\n",
    "-----\n",
    "B.- **Data normalization**\n",
    "Do it when: data is skewed and when the features analysed have different ranges. Normalization is the process of scaling individual samples to have unit norm.\n",
    "Do not do it when: data is not skewed. \n",
    "\n",
    "***Scanpy tutorial*** --> Normalize counts per cell.  \n",
    "First normalize each cell by total counts over all genes, so there's a correction by library size. This way every cell will have the same total count after normalization. In this specific tutorial the expression data is multiplied by 1e4 and then the result is normalized by applying a log-transform `sc.pp.normalize_total`. \n",
    "This normalization is specific when you have sequenced data, you have to correct by libray size so that counts become comparable among cells. The log normalization is widely used when you have skewed data. In this particular tutorial the data was transformed using *X = log(X+1)*. \n",
    "\n",
    "***Clustering tutorial*** --> Perform log transformation *on skewed columns*. The log normalization is widely used when you have skewed data. In this particular tutorial the data was transformed using *X = log(X+1)*  `np.log1p()`. \n",
    "\n",
    "-----\n",
    "C.- **Data scaling**\n",
    "In general do it when you want to transform features to be on a similar scale, that is shift the range of the feature value. If the scale is already similar do not perform it.  \n",
    "Particularly, perform *linear scaling* when the feature is more or less uniformly distributed across a fixed range. And *Z-score normalization*, when the feature distribution does not contain extreme outliers.\n",
    "\n",
    "***Scanpy tutorial*** ---> In this tutorial a *linear transformation or scaling* is applied: `sc.pp.scale()`. Linear scaling, typically uses a combination of subtraction and division to replace the original value with a number between *-1 and +1* or between *0 and 1*.\n",
    "\n",
    "***Clustering tutorial*** --> scale the features to compare the variation of the data. `StandardScaler()` Standardizes features by removing the mean and scaling to unit variance. Which is basically a Z-score normalization, which replaces the original value with a value representing the *number of standard deviations from that feature's mean*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 2. Visualization methods used:\n",
    "\n",
    "### Scanpy tutorial\n",
    "\n",
    "- **PCA**: Dimensionality reduction of the whole data. This is useful to reduce the dimensionality of the data and only keep the data from the informative principal components. In the case of the pbmc data the variance ratio plot shows that the informative pricipal components are the first 10 (the point where the curve flattens). This plot is really important because it helps define the cut-off value of the principal componets that represents most of the variance of the original data.  \n",
    "After performing the dimensionality reduction the cluster step can be applied using just the 10 principal components. `sc.pp.neighbors(pbmc, n_neighbors=10, n_pcs=10)`.  \n",
    "This visualization is useful because we passed from a matrix of n_obs × n_vars = **2,638 × 13,714** to an analysis to a clustering analysis using only **10 principal components** which preserve the data variability of the whole datset. \n",
    "\n",
    "    \n",
    "- **UMAP plot**: This plot helps you visualize the clustering analysis made (K-nearest neighbor method) colored by clusters. In this plot the number of UMAPs used is 2, so it is also a dimensionality reduction method which helps visualise of high-dimensional data.  \n",
    "The clustering is made based on the Louvain algorithm, which helps to find clusters from large networks (like the data we are analysing) taking into account the distances and the connectivities of the network.  \n",
    "The Uniform Manifold Approximation and Projection (UMAP) plot is particularly useful in this dataset becuase it helps to visually inspect the clustering results and identify potential subpopulations of cells that may represent different cell types or states.\n",
    "-----\n",
    "\n",
    "### Clustering tutorial\n",
    "\n",
    "- **Pairplot of the data**: plot a pairwise relationships in a dataset to verify that the scaling and normalization were perfomed correctly. As well as to visualise the data to have a first glance of how the data looks and if there is a really defined cluster(s). Looking at the plot of the tutorial we can see that the are approximately two categories or groups. \n",
    "\n",
    "- **Elbow plot**: Briefly, it helps to choose the number of clusters.  \n",
    "In this turorial the unlabel wine data set was clustered withing 2 clusters using K-means clustering model. This algorithm tries to find the center (centroid) of evey conglomeration of data points and assign each data point in the dataset to the closet conglomeration. Normally, when clustering you look for the clustering with the smallest inertia (the inertia is the mean squared distance between each datapoint and its closest centroid). But when finding the number of optimal cluster in which the data is grouped this does not apply, so the elbow method is applied. That is looking for the inflection point, the point in which the inertia drops very quickly before decreasing slowly at some K cluster number.  \n",
    "\n",
    "- **Hierarchical clustering**: Helps visualize the dendrogram produced by agglomerative clustering function from sklearn. So, it is important becuase we can see the separation of the wine data in a dendogram. The agglomerative clustering with `method='ward'`perfoms a hierarchical clustering with a linkage criteria based on a variance-minimizing approach, which is similar to the k-means objective function. \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance/evaluation metrics\n",
    "\n",
    "### Clustering tutorial\n",
    "\n",
    "First a test-set of the data is created using the **Stratified ShuffleSplit cross-validator**. A *stratified sampling* approach is used, that means that the wine population is divided into homogenous subgroups or *strata*. This is done because this dataset is small and with this approach the introduction of significant sampling bias is avoided. The *Stratified ShuffleSplit cross-validator* in particular creates a test set with wine quality category proportions really similar to the ones in the whole dataset. \n",
    "\n",
    "Then, the StratifiedShuffleSplit is perfomed 10 times in each data set (one that evaluates the kmeans data and the other dataset without the kmeans prediction). Afterwards, the mean of the **ROC-AUC** scores from these 10 classifiers and the **classification report** are obtained.  \n",
    "\n",
    "*Choosing a good cross-validator based on the type of data we have and analysing the mean roc-auc score after 10 runs  assures that the score value obtained is not obtained by chance. In this way we can trust the evalutation value obtained and decide which model perfomed better. \n",
    "\n",
    "---\n",
    "#### Evaluation metrics explained and why they are used:\n",
    "* **Roc-auc score**: \n",
    "    * The ROC (receiver operating characteristic) curve is used with binary classifiers. It plots the **sensitivity** (*true positive rate - TPR*) **versus 1 – specificity** (*true negative rate - TNR*).\n",
    "    * AUC measures the **area under the curve**.  \n",
    "    \n",
    "    The best way to compare classifiers is taking into account these two metrics. A random classifer will have a **ROC AUC** equal to **0.5**, whereas the closest the **ROC ACU** value gets to **1** the most accurate classifer it is.  \n",
    "  \n",
    "*Using the ROC-AUC metric is easy and relieble. It is the best option in this case because in the wine dataset we were testing a binary classifications (the wine quality is greater than 7 or not). Also, becuase the ROC-AUC method is used with linear classifier, in the tutorial the *Logistic Regression* classifer was perfomed.  \n",
    "      \n",
    "* **Classification report**:\n",
    "    It builds a text report showing the main classification metrics:\n",
    "    * **Precision**: is the accuracy of the positive predictions.  In other words, the ability of the classifier not to label as positive a sample that is negative,\n",
    "    *(true positives TP)/(true positives TP + False positives FP)*\n",
    "    * **Recall**: is the ratio of positive instances that are correctly detected by the classifier. In other words, the ability of the classifier to find all the positive samples. Also called *sensitivity* or *true positive rate TPR*\n",
    "    *(true positives TP)/(true positives TP + False negatives FN)*\n",
    "    * **f1-score**: is the combination of the precision and recall into a single metric. It is particularly useful if you need a simple way to compare two classifiers. It gives much *more weight to low values*. So, a *high F1 score* means that the classifier has *high recall and precision* values. This score favors classifiers that have similar precision and recall.\n",
    "    * **Support**: is the number of occurrences of each class in y_true.\n",
    "\n",
    "*In this case the classification report only gives us more information about the presicion and recall, it is not that important in this tutorial because we were not that worried of having a trade-off in-between these two metrics. The ROC-AUC curve was enough, but I explained the report as it used in the tutorial. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Unsupervised machine learning presentations (MDSLS) (2023):\n",
    "    * Clustering:\n",
    "        * *'0.intro.pdf'*\n",
    "        * *'1.k-means.pdf*\n",
    "* Pairplot: https://seaborn.pydata.org/generated/seaborn.pairplot.html  \n",
    "* Hierarchical clustering:  https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html#module-scipy.cluster.hierarchy\n",
    "https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering \n",
    "* hierarchy linkage: https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage\n",
    "* Classification report: https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report\n",
    "* Several other topics:  \n",
    "*GeÌ ron, A. (2019). Hands-on machine learning with Scikit-Learn, Keras and TensorFlow: concepts, tools, and techniques to build intelligent systems (2nd ed.). O'Reilly.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
